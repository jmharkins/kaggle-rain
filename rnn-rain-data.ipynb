{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(readings):\n",
    "    \"\"\"\n",
    "    Remove recordings which have ultimate gauge readings out of\n",
    "    the realm of possibility.\n",
    "\n",
    "    Parameters:\n",
    "    readings: a dataframe of gauge data with an \"expected\" column\n",
    "              representing the hourly measurement\n",
    "    returns: a copy of the original dataframe\n",
    "    \"\"\"\n",
    "    threshold = 70\n",
    "    lower_map = {i: i.lower() for i in readings.columns}\n",
    "    return (readings\n",
    "            .rename(columns=lower_map)\n",
    "            .query('expected >= @threshold')\n",
    "            .copy()\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv').pipe(remove_outliers).sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0.0000\n",
       "minutes_past             0.0000\n",
       "radardist_km             0.0000\n",
       "ref                      0.8894\n",
       "ref_5x5_10th             0.9163\n",
       "ref_5x5_50th             0.8923\n",
       "ref_5x5_90th             0.8510\n",
       "refcomposite             0.8796\n",
       "refcomposite_5x5_10th    0.9069\n",
       "refcomposite_5x5_50th    0.8834\n",
       "refcomposite_5x5_90th    0.8384\n",
       "rhohv                    0.9126\n",
       "rhohv_5x5_10th           0.9365\n",
       "rhohv_5x5_50th           0.9175\n",
       "rhohv_5x5_90th           0.8834\n",
       "zdr                      0.9126\n",
       "zdr_5x5_10th             0.9365\n",
       "zdr_5x5_50th             0.9175\n",
       "zdr_5x5_90th             0.8834\n",
       "kdp                      0.9282\n",
       "kdp_5x5_10th             0.9462\n",
       "kdp_5x5_50th             0.9300\n",
       "kdp_5x5_90th             0.9084\n",
       "expected                 0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9545.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0\n",
       "Name: expected, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('id').expected.nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vals = data.id.unique()\n",
    "train_index = np.random.choice(id_vals,\n",
    "                               size=np.ceil(len(id_vals) * (9/10.)).astype(int),\n",
    "                               replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.loc[data.id.isin(train_index), data.columns != 'expected'].fillna(0)\n",
    "test_data = data.loc[~data.id.isin(train_index), data.columns != 'expected'].fillna(0)\n",
    "train_target = data.loc[data.id.isin(train_index)].groupby('id').expected.last().values\n",
    "test_target = data.loc[~data.id.isin(train_index)].groupby('id').expected.last().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_data.groupby('id').apply(lambda x: x.values.astype('float').tolist()).tolist()\n",
    "test_array = test_data.groupby('id').apply(lambda x: x.values.astype('float').tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lens = np.asarray([len(x) for x in train_array])\n",
    "test_lens = np.asarray([len(x) for x in test_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = train_data.shape[1]\n",
    "n_steps = max([train_lens.max(), test_lens.max()])\n",
    "n_neurons = [500, 100]\n",
    "n_outputs = 1\n",
    "pad_val = np.zeros(n_inputs).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(arr):\n",
    "    for i, a in enumerate(arr):\n",
    "        alen = len(a)\n",
    "        lendiff = n_steps - alen\n",
    "        if lendiff > 0:\n",
    "            arr[i] = a + ([pad_val] * lendiff)\n",
    "    return np.asarray(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nd = pad_array(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None])\n",
    "seq_length = tf.placeholder(dtype=tf.int16, shape=[None])\n",
    "\n",
    "with tf.variable_scope('rnn', initializer=tf.contrib.layers.variance_scaling_initializer()):\n",
    "    rnn_cell_1 = tf.contrib.rnn.LSTMCell(num_units=n_neurons[0])\n",
    "    rnn_cell_2 = tf.contrib.rnn.LSTMCell(num_units=n_neurons[1])\n",
    "    multi_layer_cell = tf.contrib.rnn.MultiRNNCell([rnn_cell_1, rnn_cell_2])\n",
    "    outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32,\n",
    "                                        sequence_length=seq_length)\n",
    "    drop = tf.layers.dropout(inputs=states[1], rate=0.4)\n",
    "    y_pred = tf.layers.dense(drop, n_outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "error = (y-y_pred)\n",
    "loss = tf.reduce_mean(tf.square(error), name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "mae = tf.reduce_mean(tf.abs(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "   0  Train loss: 3346202.5000, Train MAE: 1259.00  Test MAE: 1282.03\n",
      "   1  Train loss: 3127096.0000, Train MAE: 1194.15  Test MAE: 1217.68\n",
      "   2  Train loss: 2935564.0000, Train MAE: 1157.31  Test MAE: 1179.17\n",
      "   3  Train loss: 2768169.7500, Train MAE: 1130.56  Test MAE: 1151.82\n",
      "   4  Train loss: 2616956.0000, Train MAE: 1111.56  Test MAE: 1131.57\n",
      "   5  Train loss: 2488672.2500, Train MAE: 1096.82  Test MAE: 1114.12\n",
      "   6  Train loss: 2378216.7500, Train MAE: 1088.49  Test MAE: 1103.82\n",
      "   7  Train loss: 2283448.2500, Train MAE: 1084.39  Test MAE: 1097.82\n",
      "   8  Train loss: 2202549.7500, Train MAE: 1083.16  Test MAE: 1093.65\n",
      "   9  Train loss: 2134619.7500, Train MAE: 1083.39  Test MAE: 1092.14\n",
      "  10  Train loss: 2077451.8750, Train MAE: 1086.52  Test MAE: 1091.06\n",
      "  11  Train loss: 2030436.1250, Train MAE: 1089.89  Test MAE: 1093.18\n",
      "  12  Train loss: 1991350.0000, Train MAE: 1093.16  Test MAE: 1093.17\n",
      "  13  Train loss: 1959500.8750, Train MAE: 1096.62  Test MAE: 1094.72\n",
      "  14  Train loss: 1934068.5000, Train MAE: 1101.78  Test MAE: 1097.82\n",
      "  15  Train loss: 1913601.7500, Train MAE: 1106.68  Test MAE: 1101.77\n",
      "  16  Train loss: 1897425.3750, Train MAE: 1111.55  Test MAE: 1104.91\n",
      "  17  Train loss: 1884561.7500, Train MAE: 1116.63  Test MAE: 1110.45\n",
      "  18  Train loss: 1874752.3750, Train MAE: 1121.53  Test MAE: 1111.85\n",
      "  19  Train loss: 1867055.0000, Train MAE: 1125.79  Test MAE: 1116.54\n",
      "  20  Train loss: 1861168.7500, Train MAE: 1130.24  Test MAE: 1121.10\n",
      "  21  Train loss: 1856761.6250, Train MAE: 1134.25  Test MAE: 1123.86\n",
      "  22  Train loss: 1853652.6250, Train MAE: 1137.77  Test MAE: 1127.69\n",
      "  23  Train loss: 1850758.3750, Train MAE: 1140.93  Test MAE: 1129.37\n",
      "  24  Train loss: 1849026.3750, Train MAE: 1143.54  Test MAE: 1130.72\n",
      "  25  Train loss: 1847466.6250, Train MAE: 1145.62  Test MAE: 1134.61\n",
      "  26  Train loss: 1846303.0000, Train MAE: 1147.86  Test MAE: 1135.26\n",
      "  27  Train loss: 1845154.7500, Train MAE: 1149.53  Test MAE: 1136.83\n",
      "  28  Train loss: 1844400.7500, Train MAE: 1150.78  Test MAE: 1137.21\n",
      "  29  Train loss: 1843231.8750, Train MAE: 1152.28  Test MAE: 1139.84\n",
      "  30  Train loss: 1843070.2500, Train MAE: 1152.94  Test MAE: 1140.93\n",
      "  31  Train loss: 1842157.0000, Train MAE: 1154.06  Test MAE: 1140.51\n",
      "  32  Train loss: 1841499.2500, Train MAE: 1154.66  Test MAE: 1141.21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-67578a995c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             loss_val, _ = sess.run(\n\u001b[1;32m     14\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 feed_dict={X: X_pad, seq_length: l_batch, y: y_batch})\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmae_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ml_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmae_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/johannes.harkins/anaconda/envs/kaggle-rain/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/johannes.harkins/anaconda/envs/kaggle-rain/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/johannes.harkins/anaconda/envs/kaggle-rain/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/johannes.harkins/anaconda/envs/kaggle-rain/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/johannes.harkins/anaconda/envs/kaggle-rain/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size = len(train_array) / 25\n",
    "print batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        X_batches = np.array_split(train_array, len(train_array) // batch_size)\n",
    "        l_batches = np.array_split(train_lens, len(train_lens) // batch_size)\n",
    "        y_batches = np.array_split(train_target, len(train_target) // batch_size)\n",
    "        for X_batch, l_batch, y_batch in zip(X_batches, l_batches, y_batches):\n",
    "            X_pad = pad_array(X_batch.tolist())\n",
    "            loss_val, _ = sess.run(\n",
    "                [loss, training_op],\n",
    "                feed_dict={X: X_pad, seq_length: l_batch, y: y_batch})\n",
    "        mae_train = mae.eval(feed_dict={X: X_pad, seq_length: l_batch, y: y_batch})\n",
    "        mae_test = mae.eval(feed_dict={X: test_nd, seq_length: test_lens, y: test_target})\n",
    "        print(\"{:4d}  Train loss: {:.4f}, Train MAE: {:.2f}  Test MAE: {:.2f}\".format(\n",
    "            epoch, loss_val, mae_train, mae_test))\n",
    "        saver.save(sess, \"my_reber_classifier\")\n",
    "    final_pred = y_pred.eval({X: test_nd, seq_length: test_lens, y: test_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs((final_pred - test_target)).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 183.58932495], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred[186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.47406000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
